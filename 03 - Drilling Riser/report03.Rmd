---
title: 'Estudo de Caso 03: Comparison of Rising Drilling Configurations'
author: "Equipe 04"
date: "24 de Junho de 2017"
output:
  pdf_document:
    fig_caption: yes
  word_document: default
header-includes:
- \usepackage{fancyhdr}
- \usepackage[utf8]{inputenc}
- \pagestyle{fancy}
- \fancyfoot[CO,CE]{EEE933 - Planejamento e An?lise de Experimentos}
- \fancyfoot[LE,RO]{\thepage}
csl: ieee.csl
bibliography: bibliography.bib
---  
Coordenador: Bernardo Marques   
Relator: Danny Tonidandel   
Verificador: Gustavo Vieira   
Monitor: Alessandro Cardoso

```{r setup,include=FALSE, results='hide',warning=FALSE,echo=FALSE}
if (!require(readr, quietly = TRUE)){
  install.packages("readr")
}
if (!require(car, quietly = TRUE)){
  install.packages("car")
}
if (!require(lmtest, quietly = TRUE)){
  install.packages("lmtest")
}
source('calcN.R')
library(car)
library(lmtest)

```

# 1. Descri??o do Problema
O objetivo do problema ? realizar uma compara??o entre quatro tipos de tubos de perfura??o _drilling risers_, que consiste em uma esp?cie de condu?te ou tubo utilizado para servir como passagem tempor?ria para o petr?leo extra?do em plataformas oce?nicas. Mais especificamente, pretende-se comparar o tempo m?dio at? a falha _(mean time to failure ou MTTF)_ de quatro configura??es diferentes (n?veis $A$, $B$, $C$, $D$) de equipamentos, de forma a escolher a que forne?a a menor probabilidade de falha, considerando-se um per?odo de $20$ anos. Para isto ser?o comparadas a configura??o padr?o _(Riser 1)_ com as outras tr?s, buscando encontrar qual delas prover? o maior _MTTF_. Ou seja, a quest?o a se responder ?:

Algum dos risers alternativos ? melhor que o padr?o?

A plataforma de testes escolhida pela equipe de engenharia consiste na utiliza??o de um modelo em escala para os _risers_ com um protocolo de tempo acelerado, em que h? uma rela??o direta entre o tempo medido de cada observa??o (em minutos) e a configura??o do sistema real. Todavia, o custo de cada observa??o ? significativamente custoso, sendo cerca de $US\$10.000$ (dez mil d?lares). Afim de minimizar os custos com amostras coletadas ? poss?vel utilizar os dados hist?ricos existentes para a primeira configura??o _(Riser1)_.

```{r,results='show',warning=FALSE,echo=FALSE}
## EXPERIMENTAL DEFINITIONS
v_alpha = 0.05
v_a = 4
v_k = v_a-1
v_alphaAdj = v_alpha/v_k
v_beta = 0.15
v_power = 1-v_beta
v_delta = 0.25
```
Os  par?metros experimentais desejados s?o:

* N?vel de signific?ncia: $\alpha = 0.05$;

* Tamanho de efeito de interesse pr?tico: ${d^{\star}_{t}} = 0.25$;

* Pot?ncia desejada: $(1- \beta) = \pi  \geq 0.85$.

# 2. Planejamento Experimental

Esta etapa do presente estudo de caso consiste em investigar o comportamento dos n?veis de fator a partir de uma an?lise explorat?ria, e posteriormente, aplicar um teste de compara??es m?ltiplas para as m?dias. A vari?ncia do processo ? desconhecida e ser? estimada utilizando-se os dados hist?ricos de opera??o fornecidos em <https://git.io/vHDG3. A vari?ncia ser? considerada como sendo uniforme para todas as configura??es neste estudo.

Os dados experimentais utilizados foram obtidos atrav?s de simula??o, por meio de um [aplicativo web] <http://orcslab.cpdee.ufmg.br:3838/riserdata/. A data de nascimento do segundo membro mais jovem da equipe (15/10/1992) foi o par?metro utilizado como semente para o gerador de n?meros da simula??o. Os dados gerados informam uma tabela com os n?veis de cada fator de interesse em uma coluna e os tempos (tomados em escala logar?tmica) em coluna respectiva.

Os dados est?o na escala de _log_ e ser?o analisados nesta escala, pois n?o necessitam de tranforma??o para tal.

## 2.1 An?lise de Vari?ncia
 
Para a avaliar o questionamento acima, ser? utilizada a ferramenta estat?stica para an?lise de vari?ncia denominada ANOVA.

A t?cnica ANOVA compara m?dias de diferentes amostras para verificar se estas possuem m?dias iguais ou n?o. Assim, essa t?cnica permite que v?rios grupos sejam comparados [@Campelo2015-01], [@MontgomeryRunger2011].

Em outras palavras, a an?lise de vari?ncia ? utilizada quando se quer decidir se os n?veis apresentam m?dias diferentes em rela??o ? uma m?dia global $\mu$. As diferen?as entre as m?dias dos n?veis e a m?dia global ? $\tau_i$ $\forall \  i$ . Desta forma a ANOVA se basea no teste de a hip?teses abaixo, onde quando refutado a hip?tese nula, evidencia-se ind?cios de diferen?as entre os n?veis.

Esta t?cnica ? restrita apenas ? indica??o da exist?ncia ou n?o de diferen?as entre os n?veis avaliados sem indicar quais n?veis seriam diferentes.




$$
\left\{\begin{array}{rc}
H_{0}:& \tau_i = 0, \ \ \ \forall i\\
H_{1}:& \exists \ \ \tau_i \neq 0
\end{array}\right.
$$
Esta etapa foi considerada como uma primeira verifica??o ao questionamento deste estudo por apresentar um custo de coleta de amostras menor do que o teste de compara??es m?ltiplas discutido abaixo. Portanto, caso n?o seja detectada alguma diferen?as entre os n?veis o estudo ser? conclu?do por meio do teste ANOVA.

## 2.2 Compara??es M?ltiplas

Caso a an?lise ANOVA identifique a exist?ncia de diferen?as entre os n?veis, deve-se proceder com testes de compara??o m?ltiplas todos contra um, no intuito de identificar qual ou quais n?veis apresentam tal diferen?a.

Desta forma, somente, caso a an?lise de vari?ncia indique a exist?ncia de diferen?as entre os n?veis, ser? aplicado o teste de compara??es m?ltiplas um-contra-todos (_one-vs-all_) de _Dunnett_, onde os _Risers_ propostos ser?o confrontados com a configura??o padr?o _Riser1_ para verificar se alguma proposta traria ganho de _MTTF_ frente ? configura??o j? estabelecida.

Para que se proceda com o teste de compara??es m?ltiplas, deve-se manter o controle sobre os erros do tipo-$I$ em cada compara??o. ? preciso corrigir os valores de $\alpha$ para cada teste. A escolha para este caso ? o m?todo de corre??o de Bonferroni:
$$\alpha_{adj} = \frac{\alpha_{fam?lia}}{K} \,,$$ 

no qual $K=3$ ? o n?mero de compara??es a serem feitas que no caso do teste um-contra-todos de _Dunnett_ ? confome abaixo:

$$K=a-1 \,,$$
onde $a$ ? o n?mero de n?veis, que neste do estudo ? 4 e o $\alpha$ experimental desejado ? o  $\alpha_{fam?lia} = 0.05$. Assim o valor de $\alpha_{adj} = 0.0167$


## 2.3 Defini??o do Tamanho Amostral
Para calcular o tamanho amostral, utilizaremos as mesmas rela??es utilizadas na compara??o de duas amostras independentes emparelhadas "todos contra um", alterando-se apenas os valores de $\alpha$ para os valores corrigidos $\alpha_{adj}$ para as m?ltiplas hip?teses e $a-1$ compara??es. O tamanho amostral para o teste unilateral para os risers que ser?o comparados com o j? estabelecido ? calculado como abaixo:
$$n_i = \left(1 + \frac{1}{K}\right) \left( \frac{\hat{\sigma}}{\delta^{\star}}\right)^{2}(t_{\alpha_{adj}}+t_{\beta})^{2} \,, $$
em que $t_{\alpha_{adj}}$ e $t_{\beta}$ s?o dependentes de $n$. Para solucionar esse problema, eles foram substitu?dos por $z_{\alpha_{adj}}$ e $z_{\beta}$ e a equa??o foi testada iterativamente at? a converg?ncia (implementa??o em anexo no arquivo  _calcN.R_). Dessa forma, foi encontrado o valor $n_i = 58$.

Contudo, para maximizar o poder do procedimento de m?ltiplas compara??es, o tamanho amostral do grupo de controle deve ser calculado como [@Campelo2015-01]:

$$n_0 = n_i\sqrt{K} \,,$$

Lembrando que $K$ ? o n?mero de compara??es (3), temos que $n_i = 101$


```{r,results='show',warning=FALSE,echo=FALSE}
## SAMPLE SIZE CALC
v_dataHist = readr::read_csv('riser1.csv')
v_sdHist = sd(v_dataHist$LogTTF)

v_n = calcN_oneVsAll(p_alpha = v_alphaAdj,
            p_beta = v_beta,
            p_alternative = 'one-sided',
            p_k = v_k,
            p_sd = v_sdHist,
            p_delta = v_delta
)

v_nControl = ceiling(v_n*sqrt(v_k))

v_tau = c(-v_delta*(v_a-1)/v_a, rep(v_delta/v_a, v_k))
vartau = var(v_tau)
v_nAnova = power.anova.test(groups = v_a, 
                            between.var = vartau, 
                            within.var = v_sdHist^2, 
                            sig.level = v_alpha, 
                            power = v_power)$n

v_nControl = ceiling(v_n*sqrt(v_k))

v_tau = c(-v_delta*(v_a-1)/v_a, rep(v_delta/v_a, v_k))
#v_tau = c(-v_delta/2, v_delta/2, rep(0, v_k-1))
vartau = var(v_tau)
v_nAnova = power.anova.test(groups = v_a, 
                            between.var = vartau, 
                            within.var = v_sdHist^2, 
                            sig.level = v_alpha, 
                            power = v_power)$n

```


Foi tamb?m feito o c?lculo do tamanho amostral para a t?cnica  ANOVA. Isto ? feito fazendo-se sucessivas itera??es em $n$ at? que:
$$F_{(1-\alpha)}=F_{\beta;\phi}$$
onde ambas distribui??es $F$ tem $(a-1)$ graus de liberdade no numerador e $a(n-1)$ no denomiador. O par?metro de n?o-centralidade $\phi$ ? dada por:
$$\phi=(n\sum_{i=1}^{a}\tau^2_i)/\hat\sigma^2 $$
e o valor de $\tau$ no caso de compara??es todos contra um ? dado por:
$$\tau = \left( -\frac{(a-1)\delta^{\star}}{a}, \frac{\delta^{\star}}{a}, \frac{\delta^{\star}}{a}, \frac{\delta^{\star}}{a} \right) $$
e o valor encontrado para o tamanho amostral do ANOVa ? $n=60$


Desta forma, tem-se a seguinte situa??o:

N?mero de amostras necess?rias para o ANOVA: $60*3+50=230$

N?mero de amostras necess?rias a compra??o todos contra um: $58*3 + 91 =265$

Desta forma, o pre?o para o ANOVA ? de $\$2.300.000$ e o pre?o das compara??es ? $\$2.650.000$. O ANOVA precisa de 60 amostras por grupo e as compara??es de 58 (fora o grupo controle), o que resultaria em uma sobreamostragem de 2 unidades por grupo. Por?m, caso o ANOVA n?o d? resultado de diferen?a entre os risers, seriam economizados $\$350.000$ fazendo o ANOVA antes. Essa informa??es est?o apresentadas na tabela 1.

\begin{table}[]
\centering

\begin{tabular}{|l|l|l|}
\hline
          & Melhor caso & Pior caso   \\ \hline
Com ANOVA & \$2.300.000 & \$2.710.000 \\ \hline
Sem ANOVA & \$2.650.000 & \$2.650.000 \\ \hline
Diferen?a & \$350.000   & -\$60,000   \\ \hline
\end{tabular}
\caption{An?lise de pre?o das op??es}
\label{my-label}
\end{table}

Ser? seguido o caminho com o ANOVA por causa da grande poss?vel economia e da n?o t?o significante gasto com a sobre amostragem caso o ANOVA identifique diferen?a entre os risers.

## 2.4 Tratamento e Valida??o dos Dados

Considerando o experimento realizado, foi criada uma rotina para valida??o dos dados obtidos e identifica??o de erros, onde o tempo de _MTTF_ na escala logar?tma deve ser maior que $0$. 

1. LogTTF $> 0$

Caso os valores de uma execu??o n?o atendam essas condi??es, ela seria descartada. No entanto, nenhuma das amostras apresenta problema.


# 3. An?lise Estat?stica

## 3.1 An?lise de Vari?ncia

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=4, fig.width=6}
v_data = readr::read_csv('1992-10-15_60_60_60_60.csv')
v_data$Riser = as.factor(v_data$Riser)
boxplot(LogTTF~Riser, 
        data = v_data, 
        xlab = "Riser",
        ylab = "LogTTF", 
        main = "Riser data",
        pch  = 16,
        col  = "gray")
v_model <- aov(LogTTF~Riser, 
             data = v_data)
summary.aov(v_model)
```

Como pode ser observado, o gr?fico acima n?o indica visualmente diferen?a significativa entre os n?veis. Corrobora com isto, o _F-valor = 0.608_ do teste ANOVA indicando pela n?o rejei??o da hip?tese de que n?o h? diferen?a entre os grupos.

Este resultado tamb?m indica que n?o h? necessidade de testes de compara??o m?ltiplas que verificariam quais n?veis teriam se apresentado diferentes do grupo de controle _Riser1_.

## 3.2 Valida??o das Premissas

### Normalidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=5}
shapiro.test(v_model$residuals)

qqPlot(v_model$residuals, 
       pch = 16, 
       lwd = 3, 
       cex = 2, 
       las = 1)
```

O _p-valor = 0.299_ encontrado no teste de _Shapiro-Wilk_ indica pela rejei??o normalidade das amostras
No entanto, qq plot mostra que as viola??es de normalidade s?o relativamente pequenas. A an?lise ANOVA ? robusto a pequenas varia??es de normalidade [@Campelo2015-01]. Desta forma considerou-se a premissa de normalidade atendida.

### Homocedasticidade

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
fligner.test(LogTTF~Riser, 
             data = v_data)

plot(x    = v_model$fitted.values,
     y    = v_model$residuals,
     cex  = 2,
     las  = 1,
     pch  = 16,
     xlab = "Fitted values",
     ylab = "Residuals")
grid(NULL,NULL, lwd=2, col = "#44444422")
```

O teste de igualdade de vari?ncia dos res?duos de _Fligner-Killeen_ apresentou um _p-valor = 0.1416_ o que tamb?m indica pela rejei??o da homocedasticidade das amostras.

Contudo, podemos observar no gr?fico acima, uma vari?ncia relativamente baixa entre os res?duos das amostras. Novamente com base de que a an?lise ANOVA ? robusto a pequenas varia??es tamb?m de homocedasticidade como indicado por [@Campelo2015-01], considerou-se a premissa atendida.


### Independ?ncia

```{r,results='hide',warning=FALSE,echo=FALSE, fig.height=3.5}
v_dwTest = durbinWatsonTest(v_model)
v_dwTestp = v_dwTest$p

plot(x    = seq_along(v_model$residuals),
     y    = v_model$residuals,
     type = "l",
     las  = 1,
     lwd  = 2,
     lty  = 1,
     xlab = "Residual order",
     ylab = "Residual value")
#points(x    = seq_along(v_model$residuals),
#       y    = v_model$residuals,
#       type = "p",
#       cex  = 2,
#       pch  = 5,
#       col  = as.numeric(v_data[, 2]))
grid(NA,NULL, lwd=2, col = "#44444422")
```

O plot dos valores ordenados de diferen?as de tempo entre os algoritmos n?o apresenta nenhum ind?cio de depend?ncia temporal dos valores. O teste de autocorrela??o serial Durbin-Wastson apresenta $p = `r v_dwTestp`$, o que refor?a a hip?tese de que n?o h? autocorrela??o serial entre as amostras.


# 4. Discuss?o e Conclus?es

Os testes realizados levam ?s seguintes conclus?es:

Vari?ncia entre grupos ? explicada pela vari?ncia intra grupo. N?o h? ind?cio de diferen?a significativa entre eles.

Recomenda-se manter riser 1. Custo do experimento ? significativo $(\$2.300.000)$, mas previniu um custo potencialmente maior de trocar o Riser.

# Refer?ncias